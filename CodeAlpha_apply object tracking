

# yolo_deepsort_tracking.py

import cv2
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort

# ----------------------------
# 1️⃣ Load YOLOv8 model
# ----------------------------
model = YOLO("yolov8n.pt")  # pre-trained small model

# ----------------------------
# 2️⃣ Initialize Deep SORT tracker
# ----------------------------
tracker = DeepSort(max_age=30)  # adjust max_age for longer tracking

# ----------------------------
# 3️⃣ Video source
# ----------------------------
video_source = 0  # 0 = webcam, or "video.mp4" for file
cap = cv2.VideoCapture(video_source)

if not cap.isOpened():
    print("Error: Cannot open video source")
    exit()

print("Press 'q' to quit")

# ----------------------------
# 4️⃣ Detection + Tracking loop
# ----------------------------
while True:
    ret, frame = cap.read()
    if not ret:
        print("Stream ended or cannot read frame")
        break

    # YOLO detection
    results = model(frame)[0]  # only first frame
    detections = []

    # Extract boxes and confidences
    for box in results.boxes:
        x1, y1, x2, y2 = box.xyxy[0]  # coordinates
        conf = box.conf[0].item()      # confidence
        cls = int(box.cls[0].item())   # class ID
        label = model.names[cls]
        detections.append(([x1.item(), y1.item(), x2.item(), y2.item()], conf, label))

    # Update tracker
    tracks = tracker.update_tracks(detections, frame=frame)

    # Draw tracked objects
    for track in tracks:
        if not track.is_confirmed():
            continue
        track_id = track.track_id
        ltrb = track.to_ltrb()  # left, top, right, bottom
        cls_name = track.get_det_class()
        x1, y1, x2, y2 = map(int, ltrb)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f"{cls_name}-{track_id}", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display frame
    cv2.imshow("YOLO + DeepSORT Tracking", frame)

    # Quit on 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ----------------------------
# 5️⃣ Release resources
# ----------------------------
cap.release()
cv2.destroyAllWindows()
print("Video stream closed")
